{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Boosting Methods in `tidymodels` ðŸš€\n",
    "\n",
    "And among others:\n",
    "- hyperparameter tuning using a space filling design\n",
    "- out-of-sample fit scoring\n",
    "\n",
    "First importing the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”€â”€ \u001b[1mAttaching packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6      \u001b[32mâœ”\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.5 \n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32mâœ”\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32mâœ”\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1 \n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3      \u001b[32mâœ”\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "â”€â”€ \u001b[1mAttaching packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.0.0 â”€â”€\n",
      "\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.1     \u001b[32mâœ”\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mdials       \u001b[39m 1.0.0     \u001b[32mâœ”\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34minfer       \u001b[39m 1.0.3     \u001b[32mâœ”\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32mâœ”\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.2     \u001b[32mâœ”\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.1     \n",
      "\n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34mâ€¢\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "\n",
      "Attaching package: 'foreach'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:purrr':\n",
      "\n",
      "    accumulate, when\n",
      "\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: 'vip'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:utils':\n",
      "\n",
      "    vi\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'lubridate'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"package 'bonsai' was built under R version 4.2.2\"\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(doParallel)\n",
    "library(vip)\n",
    "library(lubridate)\n",
    "library(broom)\n",
    "library(scales)\n",
    "library(bonsai)\n",
    "\n",
    "# Chart Theme\n",
    "theme_set(theme_bw() +\n",
    "          theme(plot.title = element_text(size = 14, face = \"bold\"),\n",
    "                plot.subtitle = element_text(size = 10, face = \"italic\",\n",
    "                                             colour = \"grey50\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m1003\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m7\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): sex, smoker, region\n",
      "\u001b[32mdbl\u001b[39m (4): age, bmi, children, charges\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m335\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m7\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): sex, smoker, region\n",
      "\u001b[32mdbl\u001b[39m (4): age, bmi, children, charges\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "dt_train <- read_csv(\"train.csv\", show_col_types = F)\n",
    "dt_test <- read_csv(\"test.csv\", show_col_types = F)\n",
    "folds <- vfold_cv(dt_train, v = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One quick chart\n",
    "\n",
    "This week, I started with Python and then translated to R. Therefore, I won't redo the same charts, I already did with `plotnine`, but will make a new one that would be much harder to do in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dt_train %>% \n",
    "  select(where(is.character), charges) %>% \n",
    "  pivot_longer(-charges) %>% \n",
    "  mutate(charges = charges/1000) %>% \n",
    "  ggplot(aes(charges, \n",
    "             value %>% reorder_within(charges, name),\n",
    "             fill = name)) +\n",
    "  geom_density_ridges(scale = 1.5, alpha = 0.5, size = 0.25) +\n",
    "  facet_wrap(~ name, scales = \"free\") +\n",
    "  scale_y_reordered() +\n",
    "  scale_x_continuous(labels = dollar_format(suffix = \"k\")) +\n",
    "  ggsci::scale_fill_futurama() +\n",
    "  labs(title = \"Density of Charges by Nominal Predictor Value\",\n",
    "       y = NULL, x = \"Charges\") +\n",
    "  theme(legend.position = \"none\",\n",
    "        strip.background = element_rect(fill = alpha(\"black\", 0.1)),\n",
    "        strip.text = element_text(face = \"bold\", size = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save for the markdown file\n",
    "ggsave(file = \"ridges.png\", dpi = 350, width = 6, height = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue with the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building both models in `tidymodels` includes:\n",
    "- the model specification, including the `engine` and `mode`\n",
    "- the `recipe`, including all preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "xg_wflow <- workflow() %>% \n",
    "  add_model(\n",
    "    boost_tree(trees = tune(),\n",
    "               tree_depth = tune(),\n",
    "               min_n = tune(),\n",
    "               loss_reduction = tune(),\n",
    "               sample_size = tune(),\n",
    "               mtry = tune(),\n",
    "               learn_rate = tune()) %>%\n",
    "      set_engine(\"xgboost\", importance = \"impurity\") %>%\n",
    "      set_mode(\"regression\")\n",
    "  ) %>% \n",
    "  add_recipe(\n",
    "    recipe(charges ~ ., data = dt_train) %>% \n",
    "      step_novel(all_nominal_predictors()) %>% \n",
    "      step_normalize(all_numeric_predictors()) %>% \n",
    "      step_dummy(all_nominal_predictors(), one_hot = TRUE),\n",
    "    blueprint = hardhat::default_recipe_blueprint(allow_novel_levels = TRUE)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>mean</th><th scope=col>std_err</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>rmse</td><td>4681.691</td><td>305.5070</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4720.669</td><td>279.1093</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4729.883</td><td>272.8867</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4741.291</td><td>274.6010</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4752.347</td><td>284.3850</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " .metric & mean & std\\_err & n\\\\\n",
       " <chr> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t rmse & 4681.691 & 305.5070 & 3\\\\\n",
       "\t rmse & 4720.669 & 279.1093 & 3\\\\\n",
       "\t rmse & 4729.883 & 272.8867 & 3\\\\\n",
       "\t rmse & 4741.291 & 274.6010 & 3\\\\\n",
       "\t rmse & 4752.347 & 284.3850 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| .metric &lt;chr&gt; | mean &lt;dbl&gt; | std_err &lt;dbl&gt; | n &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| rmse | 4681.691 | 305.5070 | 3 |\n",
       "| rmse | 4720.669 | 279.1093 | 3 |\n",
       "| rmse | 4729.883 | 272.8867 | 3 |\n",
       "| rmse | 4741.291 | 274.6010 | 3 |\n",
       "| rmse | 4752.347 | 284.3850 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric mean     std_err  n\n",
       "1 rmse    4681.691 305.5070 3\n",
       "2 rmse    4720.669 279.1093 3\n",
       "3 rmse    4729.883 272.8867 3\n",
       "4 rmse    4741.291 274.6010 3\n",
       "5 rmse    4752.347 284.3850 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter Tuning XGBoost\n",
    "start_time <- Sys.time()\n",
    "unregister_dopar <- function() {\n",
    "  env <- foreach:::.foreachGlobals\n",
    "  rm(list=ls(name=env), pos=env)\n",
    "}\n",
    "\n",
    "cl <- makePSOCKcluster(7)\n",
    "registerDoParallel(cl)\n",
    "\n",
    "xg_tune <- tune_grid(object = xg_wflow,\n",
    "                     resamples = folds,\n",
    "                     grid = grid_latin_hypercube(\n",
    "                       trees(),\n",
    "                       tree_depth(),\n",
    "                       min_n(),\n",
    "                       loss_reduction(),\n",
    "                       sample_size = sample_prop(),\n",
    "                       finalize(mtry(), dt_train),\n",
    "                       learn_rate(),\n",
    "                       size = 100\n",
    "                     ))\n",
    "\n",
    "stopCluster(cl)\n",
    "unregister_dopar()\n",
    "Sys.time() - start_time\n",
    "\n",
    "xg_tune %>% \n",
    "  show_best(metric = \"rmse\") %>% \n",
    "  select(.metric, mean, std_err, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# LGBM Model\n",
    "lgbm_wflow <- workflow() %>% \n",
    "  add_model(\n",
    "    boost_tree(trees = tune(),\n",
    "               tree_depth = tune(),\n",
    "               min_n = tune(),\n",
    "               loss_reduction = tune(),\n",
    "               mtry = tune(),\n",
    "               learn_rate = tune()) %>%\n",
    "      set_engine(\"lightgbm\", objective=\"mse\") %>%\n",
    "      set_mode(\"regression\")\n",
    "  ) %>% \n",
    "  add_recipe(\n",
    "    recipe(charges ~ ., data = dt_train) %>% \n",
    "      step_novel(all_nominal_predictors()) %>% \n",
    "      step_normalize(all_numeric_predictors()) %>% \n",
    "      step_dummy(all_nominal_predictors(), one_hot = TRUE),\n",
    "    blueprint = hardhat::default_recipe_blueprint(allow_novel_levels = TRUE)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>mean</th><th scope=col>std_err</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>rmse</td><td>4726.056</td><td>278.8142</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4783.247</td><td>278.2388</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4818.970</td><td>216.2120</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4832.759</td><td>304.5370</td><td>3</td></tr>\n",
       "\t<tr><td>rmse</td><td>4835.273</td><td>302.4014</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " .metric & mean & std\\_err & n\\\\\n",
       " <chr> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t rmse & 4726.056 & 278.8142 & 3\\\\\n",
       "\t rmse & 4783.247 & 278.2388 & 3\\\\\n",
       "\t rmse & 4818.970 & 216.2120 & 3\\\\\n",
       "\t rmse & 4832.759 & 304.5370 & 3\\\\\n",
       "\t rmse & 4835.273 & 302.4014 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| .metric &lt;chr&gt; | mean &lt;dbl&gt; | std_err &lt;dbl&gt; | n &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| rmse | 4726.056 | 278.8142 | 3 |\n",
       "| rmse | 4783.247 | 278.2388 | 3 |\n",
       "| rmse | 4818.970 | 216.2120 | 3 |\n",
       "| rmse | 4832.759 | 304.5370 | 3 |\n",
       "| rmse | 4835.273 | 302.4014 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric mean     std_err  n\n",
       "1 rmse    4726.056 278.8142 3\n",
       "2 rmse    4783.247 278.2388 3\n",
       "3 rmse    4818.970 216.2120 3\n",
       "4 rmse    4832.759 304.5370 3\n",
       "5 rmse    4835.273 302.4014 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter Tuning LGBM\n",
    "start_time <- Sys.time()\n",
    "unregister_dopar <- function() {\n",
    "  env <- foreach:::.foreachGlobals\n",
    "  rm(list=ls(name=env), pos=env)\n",
    "}\n",
    "\n",
    "cl <- makePSOCKcluster(7)\n",
    "registerDoParallel(cl)\n",
    "\n",
    "lgbm_tune <- tune_grid(object = lgbm_wflow,\n",
    "                       resamples = folds,\n",
    "                       grid = grid_latin_hypercube(\n",
    "                         trees(),\n",
    "                         tree_depth(),\n",
    "                         min_n(),\n",
    "                         loss_reduction(),\n",
    "                         finalize(mtry(), dt_train),\n",
    "                         learn_rate(),\n",
    "                         size = 100\n",
    "                       ))\n",
    "\n",
    "stopCluster(cl)\n",
    "unregister_dopar()\n",
    "Sys.time() - start_time\n",
    "\n",
    "lgbm_tune %>% \n",
    "  show_best(metric = \"rmse\") %>% \n",
    "  select(.metric, mean, std_err, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, the hyperparameter tuning for LGBM took a long time with `tidymodels`! Next up, fitting the models with the best hyperparameters from the tuning results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:57] WARNING: amalgamation/../src/learner.cc:627: \n",
      "Parameters: { \"importance\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the best models\n",
    "xg_fit <- xg_wflow %>% \n",
    "  finalize_workflow(select_best(xg_tune, metric = \"rmse\")) %>% \n",
    "  fit(dt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lgbm_fit <- lgbm_wflow %>% \n",
    "  finalize_workflow(select_best(lgbm_tune, metric=\"rmse\")) %>% \n",
    "  fit(dt_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `tidymodels`, it's incredibly convenient to calculate multiple evaluation metrics in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "eval_metrics <- metric_set(rsq, mae, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 3 Ã— 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>LGBM</th><th scope=col>XGBoost</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>rsq </td><td>   0.8736014</td><td>   0.8775492</td></tr>\n",
       "\t<tr><td>mae </td><td>2456.5254949</td><td>2182.5013151</td></tr>\n",
       "\t<tr><td>mape</td><td>  35.6821793</td><td>  26.4608142</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 3 Ã— 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & LGBM & XGBoost\\\\\n",
       " <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t rsq  &    0.8736014 &    0.8775492\\\\\n",
       "\t mae  & 2456.5254949 & 2182.5013151\\\\\n",
       "\t mape &   35.6821793 &   26.4608142\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 3 Ã— 3\n",
       "\n",
       "| .metric &lt;chr&gt; | LGBM &lt;dbl&gt; | XGBoost &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| rsq  |    0.8736014 |    0.8775492 |\n",
       "| mae  | 2456.5254949 | 2182.5013151 |\n",
       "| mape |   35.6821793 |   26.4608142 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric LGBM         XGBoost     \n",
       "1 rsq        0.8736014    0.8775492\n",
       "2 mae     2456.5254949 2182.5013151\n",
       "3 mape      35.6821793   26.4608142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bind_rows(\n",
    "    xg_fit %>%\n",
    "        augment(dt_test) %>%\n",
    "        mutate(model = \"XGBoost\"),\n",
    "    lgbm_fit %>%\n",
    "        augment(dt_test) %>%\n",
    "        mutate(model = \"LGBM\")\n",
    ") %>% \n",
    "  group_by(model) %>% \n",
    "  eval_metrics(truth = charges, estimate = .pred) %>% \n",
    "  select(-.estimator) %>% \n",
    "  pivot_wider(names_from = model, values_from = .estimate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to Python, `XGBoost` worked better on the holdout data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 180,
       "width": 300
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 3)\n",
    "\n",
    "bind_rows(\n",
    "    xg_fit %>%\n",
    "        augment(dt_test) %>%\n",
    "        mutate(model = \"XGBoost\"),\n",
    "    lgbm_fit %>%\n",
    "        augment(dt_test) %>%\n",
    "        mutate(model = \"LGBM\")\n",
    ") %>%\n",
    "    ggplot(aes(x = charges, y = .pred)) +\n",
    "    geom_point(alpha = 0.25, colour = \"midnightblue\") +\n",
    "    geom_abline() +\n",
    "    labs(\n",
    "        title = \"R: Predicted vs. Actuals\",\n",
    "        x = \"Actuals\", y = \"Predictions\"\n",
    "    ) +\n",
    "    facet_wrap(~model) +\n",
    "    scale_y_continuous(labels = dollar_format()) +\n",
    "    scale_x_continuous(labels = dollar_format()) +\n",
    "    theme_bw() +\n",
    "    theme(axis.text = element_text(size = 7))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for this week. Couldn't invest much more time this week because of exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggsave(file = \"R.png\", dpi = 350, width = 4, height = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
